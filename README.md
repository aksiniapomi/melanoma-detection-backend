# Melanoma Detection Backend

This FastAPI-based backend extracts ResNet50 features from three skin-cancer datasets, trains multiple classical classifiers, and serves predictions via HTTP.

---

## ğŸ“ Repository Structure

```text
.
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env
â”œâ”€â”€ alembic/                          # DB migrations
â”œâ”€â”€ app/                              # FastAPI application
â”‚   â”œâ”€â”€ main.py                       # entrypoint
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ auth/                         # authentication routes & models
â”‚   â”œâ”€â”€ patient/                      # patient CRUD
â”‚   â”œâ”€â”€ predict/                      # prediction endpoints
â”‚   â””â”€â”€ utils/                        # shared utilities
â”œâ”€â”€ data/                             # datasets & generated features
â”‚   â”œâ”€â”€ melanoma_cancer_dataset/      # original 10k images (pre-split)
â”‚   â”œâ”€â”€ ham_binary/                   # HAM10000 binary train/test/val
â”‚   â”œâ”€â”€ skin9_binary/                 # ISIC-9 binary train/test
â”‚   â””â”€â”€ cnn_features.npz              # ResNet features for train/val/test
â”œâ”€â”€ ml_models/                        # saved .joblib classifiers
â”œâ”€â”€ scripts/                          # CLI tools
â”‚   â”œâ”€â”€ data_prep/                    # prepare_ham10000.py, prepare_skin9_binary.py
â”‚   â”œâ”€â”€ feature_extraction/           # extract_features.py
â”‚   â”œâ”€â”€ training/                     # train_classifiers.py
â”‚   â”œâ”€â”€ evaluation/                   # evaluate_original_offline.py, evaluate_ham_offline.py, evaluate_skin9_offline.py, evaluate_api.py
â”‚   â””â”€â”€ utils/                        # check_splits.py, count_classes.py
â”œâ”€â”€ tests/                            # pytest suites
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md                         # â† this file
```

---

## ğŸ”§ Prerequisites

- Python 3.13  
- `git`, `curl` (for manual API checks)

---

## ğŸš€ Setup

```bash
# 1. Clone & enter
git clone https://github.com/your-org/melanoma-detection-backend.git
cd melanoma-detection-backend

# 2. Create & activate venv
python -m venv .venv
# Windows (PowerShell)
. .\.venv\Scripts\Activate.ps1
# macOS/Linux
source .venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt
```

---

## ğŸ“Š Data Preparation

```bash
# HAM10000 binary split
python scripts/data_prep/prepare_ham10000.py

# ISIC-9 binary split
python scripts/data_prep/prepare_skin9_binary.py
```

> The original 10 000-image dataset is already split into `train/` and `test/`, so no prep script is needed.

---

## ğŸ›  Feature Extraction

```bash
python scripts/feature_extraction/extract_features.py
```

Produces `data/cnn_features.npz` containing:  
- `X_train`, `y_train`  
- `X_val`,   `y_val`  
- `X_test`,  `y_test`

---

## ğŸ¤– Model Training & Evaluation

```bash
python scripts/training/train_classifiers.py \
  --model rf \
  --save-path ml_models/rf_final.joblib
```

Swap `--model` for `logistic`, `svm`, `knn`, or `dt` to train a different classifier.

---

## ğŸ“ˆ Offline Evaluation (Per Dataset)

```bash
python scripts/evaluation/evaluate_original_offline.py
python scripts/evaluation/evaluate_ham_offline.py
python scripts/evaluation/evaluate_skin9_offline.py
```

---

## ğŸŒ Live API Smoke-Tests

```bash
# Start API
uvicorn app.main:app --reload

# Health check
curl http://127.0.0.1:8000/health

# Bulk evaluation
python scripts/evaluation/evaluate_api.py
```

---

## ğŸ§ª Additional Utilities

- `scripts/utils/check_splits.py` â€” verify folder structure  
- `scripts/utils/count_classes.py` â€” count images per class  

---

## ğŸ’¾ Pushing to GitHub

```bash
git add README.md
git commit -m "docs: add full backend README"
git push origin your-branch
```
